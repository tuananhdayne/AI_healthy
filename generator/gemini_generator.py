"""
Generator s·ª≠ d·ª•ng Google Gemini API thay v√¨ Gemma local
Nhanh h∆°n v√† kh√¥ng c·∫ßn load model n·∫∑ng
"""

import os
import google.generativeai as genai
from typing import Optional

# API Key - c√≥ th·ªÉ set qua bi·∫øn m√¥i tr∆∞·ªùng GEMINI_API_KEY
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY", "AIzaSyAmRD3y8JJKEz1l79hnrmqYlu6haMKPwjk")

# Kh·ªüi t·∫°o Gemini client
try:
    genai.configure(api_key=GEMINI_API_KEY)
    # Model s·∫Ω ƒë∆∞·ª£c load lazy trong _get_model()
    _gemini_model = None
    _model_initialized = False
except Exception as e:
    print(f"‚ö†Ô∏è L·ªói khi c·∫•u h√¨nh Gemini API: {e}")
    _model_initialized = False


def _get_model():
    """Lazy load model khi c·∫ßn"""
    global _gemini_model, _model_initialized
    
    if _model_initialized and _gemini_model is not None:
        return _gemini_model
    
    try:
        # S·ª≠ d·ª•ng gemini-2.0-flash (nhanh, quota t·ªët: 15 RPM, 1M TPM)
        # C√≥ th·ªÉ ƒë·ªïi sang:
        # - gemini-2.5-pro: Ch·∫•t l∆∞·ª£ng cao nh·∫•t nh∆∞ng ch·∫≠m h∆°n (2 RPM, 125K TPM)
        # - gemini-2.5-flash: C√¢n b·∫±ng t·ªët (15 RPM, 250K TPM)
        # - gemini-2.0-flash-lite: Nh·∫π nh·∫•t (30 RPM, 1M TPM)
        model_name = os.environ.get("GEMINI_MODEL", "gemini-2.0-flash")
        _gemini_model = genai.GenerativeModel(model_name)
        _model_initialized = True
        print(f"‚úÖ Gemini API ƒë√£ s·∫µn s√†ng! (Model: {model_name})")
        return _gemini_model
    except Exception as e:
        print(f"‚ùå L·ªói khi kh·ªüi t·∫°o Gemini model: {e}")
        # Th·ª≠ fallback sang model kh√°c
        try:
            print("üîÑ ƒêang th·ª≠ model gemini-2.5-flash...")
            _gemini_model = genai.GenerativeModel('gemini-2.5-flash')
            _model_initialized = True
            print("‚úÖ Gemini API ƒë√£ s·∫µn s√†ng! (Model: gemini-2.5-flash)")
            return _gemini_model
        except Exception as e2:
            print(f"‚ùå L·ªói khi th·ª≠ model fallback: {e2}")
            raise


def generate_answer(prompt: str, system_instruction: Optional[str] = None) -> str:
    """
    Sinh c√¢u tr·∫£ l·ªùi t·ª´ Gemini API
    
    Args:
        prompt: C√¢u h·ªèi ho·∫∑c prompt c·∫ßn x·ª≠ l√Ω
        system_instruction: H∆∞·ªõng d·∫´n h·ªá th·ªëng (optional)
    
    Returns:
        C√¢u tr·∫£ l·ªùi t·ª´ Gemini
    """
    try:
        model = _get_model()
        
        # T·∫°o generation config ƒë·ªÉ t·ªëi ∆∞u cho chatbot y t·∫ø (gi·ªëng GPT)
        generation_config = genai.types.GenerationConfig(
            temperature=0.8,  # TƒÉng m·ªôt ch√∫t ƒë·ªÉ t·ª± nhi√™n h∆°n
            top_p=0.95,       # ƒêa d·∫°ng c√¢u tr·∫£ l·ªùi h∆°n
            top_k=40,         # Ch·ªçn t·ª´ top K tokens
            max_output_tokens=2048,  # TƒÉng ƒë·ªô d√†i ƒë·ªÉ tr·∫£ l·ªùi chi ti·∫øt h∆°n (gi·ªëng GPT)
        )
        
        # N·∫øu c√≥ system instruction, th√™m v√†o prompt
        full_prompt = prompt
        if system_instruction:
            full_prompt = f"{system_instruction}\n\n{prompt}"
        
        # G·ªçi API
        response = model.generate_content(
            full_prompt,
            generation_config=generation_config
        )
        
        # L·∫•y text t·ª´ response (x·ª≠ l√Ω nhi·ªÅu format)
        if hasattr(response, 'text'):
            answer = response.text.strip()
        elif hasattr(response, 'candidates') and len(response.candidates) > 0:
            if hasattr(response.candidates[0], 'content'):
                answer = response.candidates[0].content.parts[0].text.strip()
            else:
                answer = str(response.candidates[0]).strip()
        else:
            answer = str(response).strip()
        
        # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p response r·ªóng
        if not answer:
            return "Xin l·ªói, t√¥i kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi. Vui l√≤ng th·ª≠ l·∫°i."
        
        # Lo·∫°i b·ªè markdown formatting ƒë·ªÉ c√¢u tr·∫£ l·ªùi t·ª± nhi√™n h∆°n
        import re
        # Lo·∫°i b·ªè ** (bold markdown) - gi·ªØ l·∫°i n·ªôi dung b√™n trong
        answer = re.sub(r'\*\*(.*?)\*\*', r'\1', answer)
        # Lo·∫°i b·ªè c√°c d·∫•u ** c√≤n s√≥t l·∫°i (n·∫øu c√≥)
        answer = answer.replace('**', '')
        # Lo·∫°i b·ªè # (heading markdown)
        answer = re.sub(r'^#+\s*', '', answer, flags=re.MULTILINE)
        # Gi·ªØ l·∫°i bullet points (d·∫•u * ·ªü ƒë·∫ßu d√≤ng) v√¨ ƒë√≥ l√† format h·ª£p l·ªá
        
        return answer
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå L·ªói khi g·ªçi Gemini API: {error_msg}")
        
        # X·ª≠ l√Ω c√°c l·ªói th∆∞·ªùng g·∫∑p
        if "API_KEY" in error_msg or "authentication" in error_msg.lower():
            return "‚ö†Ô∏è L·ªói x√°c th·ª±c API. Vui l√≤ng ki·ªÉm tra API key."
        elif "quota" in error_msg.lower() or "rate limit" in error_msg.lower():
            return "‚ö†Ô∏è ƒê√£ v∆∞·ª£t qu√° gi·ªõi h·∫°n API. Vui l√≤ng th·ª≠ l·∫°i sau."
        else:
            return f"‚ö†Ô∏è L·ªói khi x·ª≠ l√Ω: {error_msg[:100]}"


def generate_medical_answer(
    context: str, 
    user_question: str, 
    intent: Optional[str] = None,
    conversation_history: Optional[str] = None,
    is_follow_up: bool = False,
    use_rag_priority: bool = False
) -> str:
    """
    T·∫°o c√¢u tr·∫£ l·ªùi y t·∫ø t·ªëi ∆∞u v·ªõi prompt ƒë∆∞·ª£c tinh ch·ªânh
    
    Args:
        context: Ng·ªØ c·∫£nh t·ª´ RAG retrieval
        user_question: C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
        intent: Intent ƒë√£ ph√¢n lo·∫°i (optional)
        conversation_history: L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc ƒë√≥ (optional)
        is_follow_up: C√≥ ph·∫£i c√¢u tr·∫£ l·ªùi ti·∫øp theo kh√¥ng (optional)
        use_rag_priority: N·∫øu True, ∆∞u ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ RAG (m·ª©c cao)
    
    Returns:
        C√¢u tr·∫£ l·ªùi y t·∫ø an to√†n v√† ch√≠nh x√°c
    """
    # System instruction cho chatbot y t·∫ø (gi·ªëng GPT - t·ª± nhi√™n, chi ti·∫øt, h·ªØu √≠ch)
    if use_rag_priority:
        # M·ª©c cao: ∆Øu ti√™n RAG data
        system_instruction = """B·∫°n l√† tr·ª£ l√Ω y t·∫ø chuy√™n nghi·ªáp, th√¥ng minh v√† ƒë·ªìng c·∫£m. T√¥i ƒë√£ t√¨m th·∫•y th√¥ng tin ch√≠nh x√°c trong database y t·∫ø.

PHONG C√ÅCH TR·∫¢ L·ªúI (gi·ªëng ChatGPT):
- Tr·∫£ l·ªùi T·ª∞ NHI√äN, M∆Ø·ª¢T M√Ä, D·ªÑ HI·ªÇU nh∆∞ ƒëang tr√≤ chuy·ªán v·ªõi b·∫°n
- C√≥ th·ªÉ tr·∫£ l·ªùi CHI TI·∫æT (3-8 c√¢u) khi c·∫ßn thi·∫øt ƒë·ªÉ gi·∫£i th√≠ch r√µ r√†ng
- S·ª≠ d·ª•ng ng√¥n ng·ªØ th√¢n thi·ªán, ƒë·ªìng c·∫£m nh∆∞ng v·∫´n chuy√™n nghi·ªáp
- C√≥ th·ªÉ ƒë∆∞a ra nhi·ªÅu g√≥c nh√¨n ho·∫∑c gi·∫£i th√≠ch th√™m n·∫øu h·ªØu √≠ch
- Tr·∫£ l·ªùi m·ªôt c√°ch c√≥ c·∫•u tr√∫c, d·ªÖ ƒë·ªçc (c√≥ th·ªÉ d√πng bullet points n·∫øu ph√π h·ª£p)
- QUAN TR·ªåNG: KH√îNG d√πng markdown formatting (kh√¥ng d√πng **, *, #, ho·∫∑c c√°c k√Ω hi·ªáu markdown kh√°c)
- Tr·∫£ l·ªùi b·∫±ng vƒÉn b·∫£n thu·∫ßn t√∫y, t·ª± nhi√™n, nh∆∞ ƒëang n√≥i chuy·ªán tr·ª±c ti·∫øp

QUY T·∫ÆC:
1. TR·∫¢ L·ªúI CH·ª¶ Y·∫æU D·ª∞A TR√äN TH√îNG TIN ƒê√É CUNG C·∫§P t·ª´ database
2. ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ database, c√≥ th·ªÉ b·ªï sung ki·∫øn th·ª©c chung n·∫øu c·∫ßn
3. KH√îNG ch·∫©n ƒëo√°n b·ªánh c·ª• th·ªÉ ho·∫∑c k√™ ƒë∆°n thu·ªëc
4. N·∫øu l√† c√¢u tr·∫£ l·ªùi ti·∫øp theo, KH√îNG ch√†o h·ªèi l·∫°i, tr·∫£ l·ªùi tr·ª±c ti·∫øp v√† li·ªÅn m·∫°ch
5. Lu√¥n k·∫øt th√∫c b·∫±ng l·ªùi khuy√™n ƒëi kh√°m b√°c sƒ© n·∫øu tri·ªáu ch·ª©ng nghi√™m tr·ªçng"""
    else:
        # M·ª©c th·∫•p: D√πng Gemini t·ª± do h∆°n (gi·ªëng GPT)
        system_instruction = """B·∫°n l√† tr·ª£ l√Ω y t·∫ø chuy√™n nghi·ªáp, th√¥ng minh v√† ƒë·ªìng c·∫£m. B·∫°n c√≥ ki·∫øn th·ª©c y t·∫ø r·ªông v√† kh·∫£ nƒÉng giao ti·∫øp t·ª± nhi√™n.

PHONG C√ÅCH TR·∫¢ L·ªúI:
- Tr·∫£ l·ªùi T·ª∞ NHI√äN, M∆Ø·ª¢T M√Ä, D·ªÑ HI·ªÇU nh∆∞ ƒëang tr√≤ chuy·ªán v·ªõi b·∫°n
- Phong c√°ch chuy√™n gia nh∆∞ng nh·∫π nh√†ng v√† trung t√≠nh
- C√≥ th·ªÉ tr·∫£ l·ªùi CHI TI·∫æT (3-8 c√¢u) khi c·∫ßn thi·∫øt ƒë·ªÉ gi·∫£i th√≠ch r√µ r√†ng
- S·ª≠ d·ª•ng ng√¥n ng·ªØ th√¢n thi·ªán, ƒë·ªìng c·∫£m nh∆∞ng v·∫´n chuy√™n nghi·ªáp
- Tr·∫£ l·ªùi m·ªôt c√°ch c√≥ c·∫•u tr√∫c, d·ªÖ ƒë·ªçc (c√≥ th·ªÉ d√πng bullet points n·∫øu ph√π h·ª£p)
- Nh·ªõ ƒë∆∞·ª£c ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán v√† tr·∫£ l·ªùi li·ªÅn m·∫°ch
- QUAN TR·ªåNG: KH√îNG d√πng markdown formatting (kh√¥ng d√πng **, *, #, ho·∫∑c c√°c k√Ω hi·ªáu markdown kh√°c)
- Tr·∫£ l·ªùi b·∫±ng vƒÉn b·∫£n thu·∫ßn t√∫y, t·ª± nhi√™n, nh∆∞ ƒëang n√≥i chuy·ªán tr·ª±c ti·∫øp

QUY T·∫ÆC QUAN TR·ªåNG:
1. B·∫°n KH√îNG ƒë∆∞·ª£c suy ƒëo√°n b·ªánh l√Ω
2. KH√îNG ƒë∆∞·ª£c k·∫øt lu·∫≠n tri·ªáu ch·ª©ng
3. KH√îNG ƒë∆∞·ª£c g·ª£i √Ω nguy√™n nh√¢n y t·∫ø khi ng∆∞·ªùi d√πng kh√¥ng th·∫≠t s·ª± m√¥ t·∫£ tri·ªáu ch·ª©ng r√µ r√†ng
4. N·∫øu ng∆∞·ªùi d√πng n√≥i c√¢u m∆° h·ªì ("t√¥i h∆°i kh√≥ ch·ªãu", "t√¥i kh√¥ng ·ªïn") ‚Üí Y√™u c·∫ßu h·ªç m√¥ t·∫£ r√µ h∆°n thay v√¨ t·ª± ƒëo√°n b·ªánh
5. N·∫øu ng∆∞·ªùi d√πng ch·ªâ n√≥i chuy·ªán b√¨nh th∆∞·ªùng (th·ªùi ti·∫øt, x√£ giao, chat vu v∆°) ‚Üí Tr·∫£ l·ªùi t·ª± nhi√™n v√† th√¢n thi·ªán, KH√îNG ƒë∆∞a ki·∫øn th·ª©c y t·∫ø
6. CH·ªà h·ªèi th√™m khi KH√îNG R√ï tri·ªáu ch·ª©ng, KH√îNG m·∫∑c ƒë·ªãnh h·ªèi
7. Cung c·∫•p th√¥ng tin y t·∫ø d·ª±a tr√™n ki·∫øn th·ª©c chung khi ng∆∞·ªùi d√πng h·ªèi c·ª• th·ªÉ
8. KH√îNG ch·∫©n ƒëo√°n b·ªánh c·ª• th·ªÉ ho·∫∑c k√™ ƒë∆°n thu·ªëc
9. Lu√¥n khuy·∫øn kh√≠ch ng∆∞·ªùi d√πng ƒëi kh√°m b√°c sƒ© khi c·∫ßn thi·∫øt
10. QUAN TR·ªåNG: N·∫øu ƒë√¢y l√† c√¢u tr·∫£ l·ªùi ti·∫øp theo trong cu·ªôc tr√≤ chuy·ªán, KH√îNG ch√†o h·ªèi l·∫°i, tr·∫£ l·ªùi tr·ª±c ti·∫øp v√† li·ªÅn m·∫°ch v·ªõi ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥"""
    
    # X√¢y d·ª±ng prompt v·ªõi ng·ªØ c·∫£nh
    prompt_parts = []
    
    # Th√™m l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán n·∫øu c√≥ (format r√µ r√†ng ƒë·ªÉ Gemini hi·ªÉu ng·ªØ c·∫£nh)
    if conversation_history:
        prompt_parts.append("=" * 60)
        prompt_parts.append("L·ªäCH S·ª¨ CU·ªòC TR√í CHUY·ªÜN TR∆Ø·ªöC ƒê√ì:")
        prompt_parts.append("=" * 60)
        prompt_parts.append(conversation_history)
        prompt_parts.append("=" * 60)
        prompt_parts.append("")  # D√≤ng tr·ªëng ƒë·ªÉ ph√¢n t√°ch
    
    # Th√™m th√¥ng tin y t·∫ø
    if use_rag_priority:
        prompt_parts.append(f"TH√îNG TIN Y T·∫æ T·ª™ DATABASE (∆ØU TI√äN S·ª¨ D·ª§NG):\n\n{context}\n")
    else:
        if context and context.strip() and context != "Kh√¥ng t√¨m th·∫•y th√¥ng tin c·ª• th·ªÉ trong database.":
            prompt_parts.append(f"Th√¥ng tin y t·∫ø tham kh·∫£o:\n\n{context}\n")
        else:
            prompt_parts.append("Kh√¥ng t√¨m th·∫•y th√¥ng tin c·ª• th·ªÉ trong database. H√£y tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c y t·∫ø chung.\n")
    
    # Th√™m c√¢u h·ªèi hi·ªán t·∫°i
    if is_follow_up:
        prompt_parts.append(f"üëâ C√ÇU H·ªéI/TH√îNG TIN M·ªöI C·ª¶A NG∆Ø·ªúI D√ôNG:")
        prompt_parts.append(f"{user_question}\n")
        prompt_parts.append("‚ö†Ô∏è QUAN TR·ªåNG: ƒê√¢y l√† c√¢u h·ªèi ti·∫øp theo trong cu·ªôc tr√≤ chuy·ªán. H√£y tr·∫£ l·ªùi TR·ª∞C TI·∫æP v√† LI·ªÄN M·∫†CH v·ªõi ng·ªØ c·∫£nh tr∆∞·ªõc ƒë√≥. KH√îNG ch√†o h·ªèi l·∫°i, KH√îNG l·∫∑p l·∫°i c√¢u h·ªèi ƒë√£ h·ªèi, KH√îNG gi·ªõi thi·ªáu l·∫°i b·∫£n th√¢n.")
    else:
        prompt_parts.append(f"üëâ C√ÇU H·ªéI C·ª¶A NG∆Ø·ªúI D√ôNG:")
        prompt_parts.append(f"{user_question}\n")
    
    # Th√™m h∆∞·ªõng d·∫´n tr·∫£ l·ªùi (gi·ªëng GPT - t·ª± nhi√™n, chi ti·∫øt, KH√îNG tr·∫£ l·ªùi th·ª´a)
    if use_rag_priority:
        prompt_parts.append("""H√£y tr·∫£ l·ªùi m·ªôt c√°ch T·ª∞ NHI√äN v√† CH√çNH X√ÅC (gi·ªëng ChatGPT):
- Tr·∫£ l·ªùi d·ª±a CH·ª¶ Y·∫æU tr√™n th√¥ng tin t·ª´ database ƒë√£ cung c·∫•p
- CH·ªà tr·∫£ l·ªùi nh·ªØng g√¨ li√™n quan tr·ª±c ti·∫øp ƒë·∫øn c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
- KH√îNG th√™m th√¥ng tin kh√¥ng li√™n quan ho·∫∑c kh√¥ng ƒë∆∞·ª£c h·ªèi
- KH√îNG t·ª± ƒë·ªông ƒë·ªÅ xu·∫•t c√°c ch·ªß ƒë·ªÅ kh√°c (nh∆∞ t·∫≠p luy·ªán, gi·∫£m c√¢n) n·∫øu ng∆∞·ªùi d√πng kh√¥ng h·ªèi
- C√≥ th·ªÉ gi·∫£i th√≠ch th√™m n·∫øu h·ªØu √≠ch, nh∆∞ng ph·∫£i li√™n quan ƒë·∫øn c√¢u h·ªèi
- Tr·∫£ l·ªùi ƒë·ªß d√†i ƒë·ªÉ gi·∫£i th√≠ch r√µ r√†ng (3-6 c√¢u t√πy ƒë·ªô ph·ª©c t·∫°p), KH√îNG d√†i d√≤ng
- D·ªÖ hi·ªÉu, th√¢n thi·ªán, nh∆∞ ƒëang tr√≤ chuy·ªán
- C√≥ th·ªÉ d√πng bullet points ho·∫∑c ph√¢n ƒëo·∫°n n·∫øu ph√π h·ª£p
- QUAN TR·ªåNG: KH√îNG d√πng markdown formatting (KH√îNG d√πng **, *, #, ho·∫∑c c√°c k√Ω hi·ªáu markdown)
- Tr·∫£ l·ªùi b·∫±ng vƒÉn b·∫£n thu·∫ßn t√∫y, t·ª± nhi√™n, kh√¥ng d√πng d·∫•u ** ƒë·ªÉ l√†m ƒë·∫≠m ch·ªØ
- Kh√¥ng ch·∫©n ƒëo√°n hay k√™ thu·ªëc
- N·∫øu l√† c√¢u tr·∫£ l·ªùi ti·∫øp theo, tr·∫£ l·ªùi tr·ª±c ti·∫øp, kh√¥ng ch√†o h·ªèi l·∫°i

Tr·∫£ l·ªùi:""")
    else:
        prompt_parts.append("""H√£y tr·∫£ l·ªùi m·ªôt c√°ch T·ª∞ NHI√äN v√† CH√çNH X√ÅC:
- Tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c y t·∫ø chung
- CH·ªà tr·∫£ l·ªùi nh·ªØng g√¨ li√™n quan tr·ª±c ti·∫øp ƒë·∫øn c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
- KH√îNG th√™m th√¥ng tin kh√¥ng li√™n quan ho·∫∑c kh√¥ng ƒë∆∞·ª£c h·ªèi
- KH√îNG t·ª± ƒë·ªông ƒë·ªÅ xu·∫•t c√°c ch·ªß ƒë·ªÅ kh√°c n·∫øu ng∆∞·ªùi d√πng kh√¥ng h·ªèi
- QUAN TR·ªåNG: N·∫øu c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng M∆† H·ªí ho·∫∑c KH√îNG R√ï R√ÄNG v·ªÅ tri·ªáu ch·ª©ng ‚Üí CH·ªà KHI ƒê√ì m·ªõi h·ªèi th√™m ƒë·ªÉ l√†m r√µ. KH√îNG m·∫∑c ƒë·ªãnh h·ªèi.
- N·∫øu ng∆∞·ªùi d√πng ch·ªâ n√≥i chuy·ªán b√¨nh th∆∞·ªùng (kh√¥ng ph·∫£i v·ªÅ y t·∫ø) ‚Üí Tr·∫£ l·ªùi t·ª± nhi√™n, th√¢n thi·ªán, KH√îNG ƒë∆∞a ki·∫øn th·ª©c y t·∫ø
- N·∫øu ng∆∞·ªùi d√πng m√¥ t·∫£ tri·ªáu ch·ª©ng r√µ r√†ng ‚Üí Tr·∫£ l·ªùi d·ª±a tr√™n ki·∫øn th·ª©c y t·∫ø, KH√îNG suy ƒëo√°n b·ªánh
- Tr·∫£ l·ªùi ƒë·ªß d√†i ƒë·ªÉ gi·∫£i th√≠ch r√µ r√†ng (3-6 c√¢u t√πy ƒë·ªô ph·ª©c t·∫°p), KH√îNG d√†i d√≤ng
- D·ªÖ hi·ªÉu, th√¢n thi·ªán, nh∆∞ ƒëang tr√≤ chuy·ªán
- C√≥ th·ªÉ d√πng bullet points ho·∫∑c ph√¢n ƒëo·∫°n n·∫øu ph√π h·ª£p
- QUAN TR·ªåNG: KH√îNG d√πng markdown formatting (KH√îNG d√πng **, *, #, ho·∫∑c c√°c k√Ω hi·ªáu markdown)
- Tr·∫£ l·ªùi b·∫±ng vƒÉn b·∫£n thu·∫ßn t√∫y, t·ª± nhi√™n, kh√¥ng d√πng d·∫•u ** ƒë·ªÉ l√†m ƒë·∫≠m ch·ªØ
- KH√îNG ch·∫©n ƒëo√°n hay k√™ thu·ªëc
- KH√îNG suy ƒëo√°n b·ªánh l√Ω hay k·∫øt lu·∫≠n tri·ªáu ch·ª©ng
- K·∫øt th√∫c b·∫±ng l·ªùi khuy√™n ƒëi kh√°m b√°c sƒ© n·∫øu tri·ªáu ch·ª©ng nghi√™m tr·ªçng
- N·∫øu l√† c√¢u tr·∫£ l·ªùi ti·∫øp theo, tr·∫£ l·ªùi tr·ª±c ti·∫øp, kh√¥ng ch√†o h·ªèi l·∫°i

Tr·∫£ l·ªùi:""")
    
    prompt = "\n".join(prompt_parts)
    
    return generate_answer(prompt, system_instruction=system_instruction)


def generate_greeting(user_greeting: str) -> str:
    """
    T·∫°o c√¢u tr·∫£ l·ªùi ch√†o h·ªèi t·ª± nhi√™n
    """
    prompt = f"""Ng∆∞·ªùi d√πng ch√†o h·ªèi: "{user_greeting}"

H√£y tr·∫£ l·ªùi ch√†o h·ªèi m·ªôt c√°ch th√¢n thi·ªán, ng·∫Øn g·ªçn (1-2 c√¢u) b·∫±ng ti·∫øng Vi·ªát.
Gi·ªõi thi·ªáu b·∫°n l√† tr·ª£ l√Ω y t·∫ø v√† s·∫µn s√†ng h·ªó tr·ª£.

Tr·∫£ l·ªùi:"""
    
    system_instruction = "B·∫°n l√† tr·ª£ l√Ω y t·∫ø th√¢n thi·ªán, chuy√™n nghi·ªáp. Tr·∫£ l·ªùi ng·∫Øn g·ªçn, t·ª± nhi√™n."
    
    return generate_answer(prompt, system_instruction=system_instruction)

