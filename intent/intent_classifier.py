from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F


class IntentClassifier:
    def __init__(self, model_path):
        print("üîÑ Loading PhoBERT Intent Model...")

        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(
            model_path,
            torch_dtype=torch.float32,
            device_map="auto"
        )
        self.model.eval()

        # Map ID ‚Üí label (theo model m·ªõi)
        self.id2label = {
            0: "bao_dau_bung",
            1: "bao_dau_dau",
            2: "bao_ho",
            3: "bao_met_moi",
            4: "bao_sot",
            5: "lo_lang_stress",
            6: "other",
            7: "tu_van_dinh_duong",
            8: "tu_van_tap_luyen"
        }

    # ------------------------
    # Ch·ªâ tr·∫£ v·ªÅ nh√£n intent
    # ------------------------
    def predict_intent(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True).to(self.model.device)
        with torch.no_grad():
            logits = self.model(**inputs).logits
            pred_id = torch.argmax(logits, dim=1).item()

        return self.id2label.get(pred_id, "unknown")

    # ------------------------
    # Tr·∫£ v·ªÅ nh√£n + ƒë·ªô tin c·∫≠y
    # ------------------------
    def predict_with_conf(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True).to(self.model.device)

        with torch.no_grad():
            logits = self.model(**inputs).logits
            probs = F.softmax(logits, dim=1)

        conf, pred_id = torch.max(probs, dim=1)
        pred_id = pred_id.item()
        conf = conf.item()

        # X·ª≠ l√Ω an to√†n ‚Äî h·ªó tr·ª£ key l√† s·ªë ho·∫∑c chu·ªói
        label = (
            self.id2label.get(pred_id) or
            self.id2label.get(str(pred_id)) or
            "unknown"
        )

        return label, conf
