# chatbot.py

from threading import Lock
from typing import Any, Dict, Optional

from intent.intent_classifier import IntentClassifier
from rag.retriever import Retriever
from generator.gemini_generator import generate_medical_answer
from app.response_layer import need_more_info, build_clarification_question
from app.symptom_extractor import extract_symptoms
from app.risk_estimator import estimate_risk

# ============================
# KHá»I Táº O CÃC MODEL (LAZY LOADING)
# ============================

intent_model_path = r"D:\CHAT BOT TTCS\model\intent_model"
rag_path = r"D:\CHAT BOT TTCS\rag"

# KhÃ´ng load models ngay khi import - sáº½ load khi cáº§n
intent_classifier: Optional[IntentClassifier] = None
retriever: Optional[Retriever] = None
_models_initialized = False
_models_lock = Lock()

conversation_states: Dict[str, Dict[str, Any]] = {}
conversation_lock = Lock()


def _ensure_models_loaded():
    """Äáº£m báº£o models Ä‘Ã£ Ä‘Æ°á»£c load"""
    global intent_classifier, retriever, _models_initialized
    
    if _models_initialized:
        return
    
    with _models_lock:
        if _models_initialized:  # Double check
            return
        
        print("ğŸ”„ Äang khá»Ÿi táº¡o models trong chatbot module...")
        
        # Load Intent Classifier
        if intent_classifier is None:
            intent_classifier = IntentClassifier(intent_model_path)
        
        # Load RAG Retriever
        if retriever is None:
            retriever = Retriever(rag_path)
        
        # Gemini API khÃ´ng cáº§n load model, chá»‰ cáº§n kiá»ƒm tra API key
        from generator.gemini_generator import _get_model
        try:
            _get_model()  # Test API connection
        except Exception as e:
            print(f"âš ï¸ Cáº£nh bÃ¡o: KhÃ´ng thá»ƒ káº¿t ná»‘i Gemini API: {e}")
            print("   Há»‡ thá»‘ng váº«n sáº½ hoáº¡t Ä‘á»™ng nhÆ°ng cÃ³ thá»ƒ gáº·p lá»—i khi generate answer")
        
        _models_initialized = True
        print("âœ… Models trong chatbot module Ä‘Ã£ sáºµn sÃ ng!")

# Chá»‰ in message nÃ y khi cháº¡y trá»±c tiáº¿p (khÃ´ng pháº£i khi import)
if __name__ == "__main__":
    # Khi cháº¡y trá»±c tiáº¿p, load models ngay
    _ensure_models_loaded()
    print("ğŸ¤– Chatbot y táº¿ sáºµn sÃ ng. Nháº­p 'quit' Ä‘á»ƒ thoÃ¡t.\n")


# ============================
# QUáº¢N LÃ TRáº NG THÃI Há»˜I THOáº I
# ============================


def _get_or_create_state(session_id: str) -> Dict[str, Any]:
    with conversation_lock:
        if session_id not in conversation_states:
            conversation_states[session_id] = {
                "last_intent": None,
                "last_symptoms": None,
                "conversation_history": []  # LÆ°u lá»‹ch sá»­ há»™i thoáº¡i (tá»‘i Ä‘a 5 cáº·p Q&A gáº§n nháº¥t)
            }
        return conversation_states[session_id]


def reset_conversation(session_id: str) -> None:
    with conversation_lock:
        conversation_states.pop(session_id, None)


# ============================
# HÃ€M CHAT CHÃNH
# ============================


def run_chat_pipeline(user_input: str, session_id: str = "default", user_id: Optional[str] = None) -> Dict[str, Any]:
    # Äáº£m báº£o models Ä‘Ã£ Ä‘Æ°á»£c load
    _ensure_models_loaded()
    
    cleaned_input = (user_input or "").strip()

    if not cleaned_input:
        return {
            "session_id": session_id,
            "reply": "Báº¡n hÃ£y nháº­p cÃ¢u há»i hoáº·c mÃ´ táº£ triá»‡u chá»©ng cá»¥ thá»ƒ hÆ¡n nhÃ©.",
            "intent": None,
            "intent_confidence": 0.0,
            "symptoms": {},
            "risk": None,
            "clarification_needed": False,
            "clarification_question": None,
            "sources": [],
            "stage": "validation"
        }

    state = _get_or_create_state(session_id)

    # 1) Intent
    intent, intent_conf = intent_classifier.predict_with_conf(cleaned_input)
    print(f"ğŸ§  Intent: {intent} | conf={intent_conf:.2f}")

    # 2) Symptom Extraction
    symptoms = extract_symptoms(cleaned_input)
    risk = estimate_risk(symptoms)

    # 3) LÆ°u vÃ o memory
    state["last_intent"] = intent
    state["last_symptoms"] = symptoms
    state["last_user_input"] = cleaned_input
    
    # LÆ°u user input vÃ o conversation history ngay (trÆ°á»›c khi generate reply)
    history_list = state.get("conversation_history", [])
    # LÆ°u user input vá»›i bot reply = None (sáº½ cáº­p nháº­t sau)
    history_list.append((cleaned_input, None))
    state["conversation_history"] = history_list

    response: Dict[str, Any] = {
        "session_id": session_id,
        "intent": intent,
        "intent_confidence": float(intent_conf),
        "symptoms": symptoms,
        "risk": risk,
        "clarification_needed": False,
        "clarification_question": None,
        "sources": [],
        "stage": "generation"
    }

    # 4) NgÆ°á»i dÃ¹ng nÃ³i tiáº¿p cÃ¡c tá»« mÆ¡ há»“: "váº«n tháº¿", "Ä‘á»¡ hÆ¡n rá»“i"
    if cleaned_input.lower() in ["váº«n tháº¿", "nhÆ° hÃ´m qua", "Ä‘á»¡ hÆ¡n", "náº·ng hÆ¡n"]:
        last = state.get("last_symptoms")
        if last:
            response["reply"] = (
                "ğŸ’¬ Báº¡n Ä‘ang nÃ³i vá» triá»‡u chá»©ng trÆ°á»›c Ä‘Ã³. Báº¡n cÃ³ thá»ƒ mÃ´ táº£ thÃªm khÃ´ng? "
                f"MÃ¬nh ghi nháº­n láº§n trÆ°á»›c lÃ : {last}"
            )
        else:
            response["reply"] = "Báº¡n mÃ´ táº£ triá»‡u chá»©ng hiá»‡n táº¡i rÃµ hÆ¡n nhÃ©!"
        response["stage"] = "follow_up"
        return response

    # 5) RISK LAYER â€” phÃ¡t hiá»‡n nguy hiá»ƒm
    if risk == "high":
        danger_signs = symptoms.get("danger_signs") or []
        danger_text = ", ".join(danger_signs) if danger_signs else "dáº¥u hiá»‡u nguy hiá»ƒm"
        response["reply"] = (
            "âš ï¸ MÃ¬nh phÃ¡t hiá»‡n cÃ³ dáº¥u hiá»‡u nguy hiá»ƒm nhÆ°: "
            + danger_text
            + ". Báº¡n nÃªn Ä‘i khÃ¡m bÃ¡c sÄ© cÃ ng sá»›m cÃ ng tá»‘t Ä‘á»ƒ Ä‘áº£m báº£o an toÃ n."
        )
        response["stage"] = "safety"
        return response

    # 6) CLARIFICATION LAYER â€” chá»‰ há»i khi thá»±c sá»± khÃ´ng rÃµ triá»‡u chá»©ng
    # KHÃ”NG há»i máº·c Ä‘á»‹nh, chá»‰ há»i khi cÃ¢u ráº¥t mÆ¡ há»“
    if need_more_info(cleaned_input, intent):
        question = build_clarification_question(intent)
        response["reply"] = (
            "ğŸ’¬ Äá»ƒ hiá»ƒu rÃµ hÆ¡n vÃ  tráº£ lá»i chÃ­nh xÃ¡c, báº¡n cho mÃ¬nh biáº¿t thÃªm nhÃ©:\n"
            f"{question}"
        )
        response["clarification_needed"] = True
        response["clarification_question"] = question
        response["stage"] = "clarification"
        # LÆ°u cÃ¢u há»i clarification vÃ o state
        state["last_clarification_question"] = question
        state["last_user_input_before_clarification"] = cleaned_input
        return response

    # 7) RAG RETRIEVAL - TÃ¬m thÃ´ng tin trong database
    # Logic má»›i: Náº¿u intent confidence >= 0.998 â†’ search RAG theo intent
    # Náº¿u intent lÃ  "other"/"unknown" hoáº·c confidence < 0.98 â†’ dÃ¹ng Gemini tá»± do
    
    use_rag = False
    context = ""
    docs = []
    
    # Kiá»ƒm tra intent confidence
    if intent_conf >= 0.998 and intent not in ["other", "unknown"]:
        # Intent confidence cao â†’ search RAG theo intent
        print(f"âœ… Intent confidence cao ({intent_conf:.3f}), search RAG theo intent: {intent}")
        try:
            docs = retriever.search_by_intent(intent, cleaned_input, k=5)  # TÄƒng tá»« 3 lÃªn 5 Ä‘á»ƒ cÃ³ nhiá»u context hÆ¡n
            response["sources"] = docs
            
            # TÃ­nh confidence tá»« RAG results
            rag_confidence = docs[0]["confidence"] if docs else 0.0
            rag_cosine = docs[0]["cosine"] if docs else -1.0
            
            print(f"ğŸ“š RAG Confidence: {rag_confidence:.3f} | Cosine: {rag_cosine:.3f}")
            
            # XÃ¢y dá»±ng context tá»« RAG
            context = "\n".join([d["text"] for d in docs]) if docs else ""
            use_rag = True
        except Exception as e:
            print(f"âš ï¸ Lá»—i khi search RAG theo intent: {e}, fallback vá» search thÃ´ng thÆ°á»ng")
            docs = retriever.search(cleaned_input, k=5)  # TÄƒng tá»« 3 lÃªn 5
            response["sources"] = docs
            context = "\n".join([d["text"] for d in docs]) if docs else ""
            use_rag = True
    elif intent in ["other", "unknown"] or intent_conf < 0.98:
        # Intent lÃ  "other"/"unknown" hoáº·c confidence tháº¥p â†’ dÃ¹ng Gemini tá»± do (khÃ´ng search RAG)
        print(f"âš ï¸ Intent '{intent}' vá»›i confidence {intent_conf:.3f} < 0.98, dÃ¹ng Gemini tá»± do")
        response["sources"] = []
        context = ""  # KhÃ´ng cÃ³ context tá»« RAG
        use_rag = False
    else:
        # TrÆ°á»ng há»£p khÃ¡c: search RAG thÃ´ng thÆ°á»ng
        docs = retriever.search(cleaned_input, k=5)  # TÄƒng tá»« 3 lÃªn 5 Ä‘á»ƒ cÃ³ nhiá»u context hÆ¡n
        response["sources"] = docs
        
        # TÃ­nh confidence tá»« RAG results
        rag_confidence = docs[0]["confidence"] if docs else 0.0
        rag_cosine = docs[0]["cosine"] if docs else -1.0
        
        print(f"ğŸ“š RAG Confidence: {rag_confidence:.3f} | Cosine: {rag_cosine:.3f}")
        
        # XÃ¢y dá»±ng context tá»« RAG
        context = "\n".join([d["text"] for d in docs]) if docs else ""
        use_rag = True

    # 8) Láº¤Y HEALTH PROFILE (náº¿u cÃ³ user_id)
    health_profile_context = ""
    if user_id:
        try:
            from firestore_service import get_health_profile
            profile = get_health_profile(user_id)
            if profile:
                # TÃ­nh BMI
                chieu_cao_m = profile.get('chieuCao', 0) / 100
                can_nang = profile.get('canNang', 0)
                bmi = can_nang / (chieu_cao_m ** 2) if chieu_cao_m > 0 else 0
                
                # XÃ¡c Ä‘á»‹nh category BMI
                if bmi < 18.5:
                    bmi_category = "hÆ¡i gáº§y"
                elif bmi < 25:
                    bmi_category = "cÃ¢n Ä‘á»‘i"
                elif bmi < 30:
                    bmi_category = "hÆ¡i thá»«a cÃ¢n"
                else:
                    bmi_category = "thá»«a cÃ¢n nhiá»u"
                
                # Chuyá»ƒn Ä‘á»•i má»©c váº­n Ä‘á»™ng
                muc_van_dong_labels = {
                    'it': 'Ãt',
                    'vua': 'Vá»«a',
                    'nhieu': 'Nhiá»u'
                }
                muc_van_dong_label = muc_van_dong_labels.get(profile.get('mucVanDong', 'it'), 'Ãt')
                
                # Chuyá»ƒn Ä‘á»•i giá»›i tÃ­nh
                gioi_tinh_labels = {
                    'nam': 'Nam',
                    'nu': 'Ná»¯',
                    'khac': 'KhÃ¡c'
                }
                gioi_tinh_label = gioi_tinh_labels.get(profile.get('gioiTinh', 'khac'), 'KhÃ¡c')
                
                # Táº¡o health profile context
                health_profile_context = f"""[PROFILE]
Tuá»•i: {profile.get('tuoi', 'N/A')}
Giá»›i tÃ­nh: {gioi_tinh_label}
Chiá»u cao: {profile.get('chieuCao', 'N/A')} cm
CÃ¢n náº·ng: {profile.get('canNang', 'N/A')} kg
Má»©c váº­n Ä‘á»™ng: {muc_van_dong_label}
BMI: {bmi:.1f} ({bmi_category})
[/PROFILE]

Dá»±a vÃ o há»“ sÆ¡ trÃªn, hÃ£y Ä‘Æ°a ra gá»£i Ã½ táº­p luyá»‡n nháº¹, an toÃ n, dá»… thá»±c hiá»‡n phÃ¹ há»£p vá»›i:
- BMI: {bmi_category} ({bmi:.1f})
- Giá»›i tÃ­nh: {gioi_tinh_label}
- Má»©c váº­n Ä‘á»™ng hiá»‡n táº¡i: {muc_van_dong_label}
- Tuá»•i: {profile.get('tuoi', 'N/A')}

QUAN TRá»ŒNG: KhÃ´ng Ä‘Æ°á»£c cháº©n Ä‘oÃ¡n bá»‡nh, khÃ´ng Ä‘Æ°á»£c gá»£i Ã½ thuá»‘c. Chá»‰ Ä‘Æ°a ra lá»i khuyÃªn táº­p luyá»‡n vÃ  lá»‘i sá»‘ng nháº¹ nhÃ ng, an toÃ n.

"""
                print(f"ğŸ“‹ ÄÃ£ load health profile cho user {user_id[:8]}... (BMI: {bmi:.1f}, {bmi_category})")
        except Exception as e:
            print(f"âš ï¸ KhÃ´ng thá»ƒ load health profile: {e}")
            health_profile_context = ""

    # 10) PHÃ‚N Táº¦NG TRáº¢ Lá»œI
    # Má»©c 1: RAG confidence cao (>= 0.7) â†’ Tráº£ lá»i dá»±a vÃ o data
    # Má»©c 2: RAG confidence tháº¥p (< 0.7) â†’ DÃ¹ng Gemini
    # Má»©c 3: Risk cao hoáº·c khÃ´ng cháº¯c cháº¯n â†’ Tráº£ lá»i an toÃ n, khuyÃªn gáº·p bÃ¡c sÄ©
    
    # XÃ¢y dá»±ng conversation history Ä‘á»ƒ bot nhá»› ngá»¯ cáº£nh (giá»‘ng GPT - nhá»› nhiá»u vÃ²ng há»™i thoáº¡i)
    conversation_history = None
    is_follow_up = False
    
    # Láº¥y lá»‹ch sá»­ há»™i thoáº¡i tá»« state (tá»‘i Ä‘a 5 cáº·p Q&A gáº§n nháº¥t)
    history_list = state.get("conversation_history", [])
    
    # Lá»c bá» entry cuá»‘i cÃ¹ng náº¿u chÆ°a cÃ³ reply (Ä‘Ã³ lÃ  cÃ¢u há»i hiá»‡n táº¡i)
    # Chá»‰ láº¥y cÃ¡c cáº·p Q&A Ä‘Ã£ hoÃ n chá»‰nh
    complete_history = [(q, a) for q, a in history_list if a is not None]
    
    # Debug: In ra conversation history Ä‘á»ƒ kiá»ƒm tra
    if complete_history:
        print(f"ğŸ“ Conversation history cÃ³ {len(complete_history)} cáº·p Q&A:")
        for i, (q, a) in enumerate(complete_history[-3:], 1):
            print(f"   {i}. User: {q[:50]}... | Bot: {a[:50] if a else 'None'}...")
    
    # Kiá»ƒm tra xem cÃ³ pháº£i cÃ¢u tráº£ lá»i tiáº¿p theo sau clarification khÃ´ng
    last_clarification_question = state.get("last_clarification_question")
    last_user_input_before_clarification = state.get("last_user_input_before_clarification")
    last_intent = state.get("last_intent")
    last_symptoms = state.get("last_symptoms")
    
    # XÃ¢y dá»±ng conversation history tá»« nhiá»u nguá»“n
    history_parts = []
    
    # 1. Náº¿u cÃ³ clarification question trÆ°á»›c Ä‘Ã³
    if last_clarification_question and last_user_input_before_clarification:
        is_follow_up = True
        history_parts.append("Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n:")
        history_parts.append(f"ğŸ‘¤ NgÆ°á»i dÃ¹ng: \"{last_user_input_before_clarification}\"")
        history_parts.append(f"ğŸ¤– Báº¡n: \"{last_clarification_question}\"")
        history_parts.append(f"\nğŸ‘‰ BÃ¢y giá» ngÆ°á»i dÃ¹ng tráº£ lá»i: \"{cleaned_input}\"")
    # 2. Náº¿u cÃ³ lá»‹ch sá»­ há»™i thoáº¡i tá»« cÃ¡c láº§n trÆ°á»›c (Q&A Ä‘Ã£ hoÃ n chá»‰nh)
    elif complete_history:
        is_follow_up = True
        history_parts.append("Lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n trÆ°á»›c Ä‘Ã³:")
        # Láº¥y 4-5 cáº·p gáº§n nháº¥t Ä‘á»ƒ cÃ³ Ä‘á»§ ngá»¯ cáº£nh
        for i, (q, a) in enumerate(complete_history[-5:], 1):
            history_parts.append(f"\n[{i}] ğŸ‘¤ NgÆ°á»i dÃ¹ng: {q}")
            history_parts.append(f"    ğŸ¤– Báº¡n: {a}")
        history_parts.append(f"\nğŸ‘‰ BÃ¢y giá» ngÆ°á»i dÃ¹ng há»i: \"{cleaned_input}\"")
    # 3. Náº¿u cÃ³ thÃ´ng tin tá»« láº§n trÆ°á»›c (intent, symptoms) nhÆ°ng chÆ°a cÃ³ history Ä‘áº§y Ä‘á»§
    elif last_intent and last_symptoms and not complete_history:
        is_follow_up = True
        history_parts.append("ThÃ´ng tin tá»« cuá»™c trÃ² chuyá»‡n trÆ°á»›c:")
        history_parts.append(f"ğŸ‘¤ NgÆ°á»i dÃ¹ng Ä‘Ã£ mÃ´ táº£ vá»: {last_intent}")
        if last_symptoms.get("location"):
            history_parts.append(f"   - Vá»‹ trÃ­: {last_symptoms.get('location')}")
        if last_symptoms.get("intensity"):
            history_parts.append(f"   - Má»©c Ä‘á»™: {last_symptoms.get('intensity')}")
        history_parts.append(f"\nğŸ‘‰ BÃ¢y giá» ngÆ°á»i dÃ¹ng há»i: \"{cleaned_input}\"")
    
    if history_parts:
        conversation_history = "\n".join(history_parts)
        is_follow_up = True  # Äáº£m báº£o is_follow_up = True náº¿u cÃ³ history

    # 9) THÃŠM HEALTH PROFILE CONTEXT VÃ€O CONTEXT (náº¿u cÃ³)
    if health_profile_context:
        # ThÃªm health profile context vÃ o Ä‘áº§u context
        if context:
            context = health_profile_context + "\n\n" + context
        else:
            context = health_profile_context

    # 11) PHÃ‚N Táº¦NG TRáº¢ Lá»œI
    # Logic má»›i: Náº¿u Ä‘Ã£ search RAG theo intent (confidence >= 0.998) â†’ dÃ¹ng RAG
    # Náº¿u intent lÃ  "other"/"unknown" hoáº·c confidence < 0.98 â†’ dÃ¹ng Gemini tá»± do
    
    if use_rag and context:
        # ÄÃ£ search RAG theo intent â†’ tráº£ lá»i dá»±a vÃ o RAG
        rag_confidence = docs[0]["confidence"] if docs else 0.0
        print(f"âœ… DÃ¹ng RAG vá»›i confidence: {rag_confidence:.3f}")
        response["stage"] = "rag_high_confidence"
        response["reply"] = generate_medical_answer(
            context=context,
            user_question=cleaned_input,
            intent=intent,
            conversation_history=conversation_history,
            is_follow_up=is_follow_up,
            use_rag_priority=True  # Æ¯u tiÃªn sá»­ dá»¥ng RAG context
        )
    else:
        # Intent lÃ  "other"/"unknown" hoáº·c confidence < 0.98 â†’ dÃ¹ng Gemini tá»± do
        print("âš ï¸ DÃ¹ng Gemini tá»± do (khÃ´ng cÃ³ RAG context)")
        response["stage"] = "gemini_fallback"
        response["reply"] = generate_medical_answer(
            context="",  # KhÃ´ng cÃ³ context tá»« RAG
            user_question=cleaned_input,
            intent=intent,
            conversation_history=conversation_history,
            is_follow_up=is_follow_up,
            use_rag_priority=False  # KhÃ´ng Æ°u tiÃªn RAG, Ä‘á»ƒ Gemini tá»± do
        )
    
    # Má»©c ná»¯a: Náº¿u risk cao hoáº·c intent confidence tháº¥p â†’ Tráº£ lá»i an toÃ n
    if risk == "high" or (intent_conf < 0.5 and response["stage"] not in ["safety", "rag_high_confidence"]):
        print("ğŸ›¡ï¸ Má»©c ná»¯a: Risk cao hoáº·c khÃ´ng cháº¯c cháº¯n, tráº£ lá»i an toÃ n")
        safety_message = (
            "âš ï¸ Dá»±a trÃªn thÃ´ng tin báº¡n cung cáº¥p, tÃ´i khuyÃªn báº¡n nÃªn Ä‘i gáº·p bÃ¡c sÄ© Ä‘á»ƒ Ä‘Æ°á»£c "
            "tÆ° váº¥n vÃ  kiá»ƒm tra chÃ­nh xÃ¡c. TÃ´i chá»‰ cÃ³ thá»ƒ cung cáº¥p thÃ´ng tin tham kháº£o, "
            "khÃ´ng thá»ƒ thay tháº¿ cho cháº©n Ä‘oÃ¡n y táº¿ chuyÃªn nghiá»‡p.\n\n"
        )
        if response["reply"]:
            response["reply"] = safety_message + response["reply"]
        else:
            response["reply"] = safety_message + "Vui lÃ²ng liÃªn há»‡ vá»›i bÃ¡c sÄ© cÃ ng sá»›m cÃ ng tá»‘t."
        response["stage"] = "safety_recommendation"
    
    # Cáº­p nháº­t conversation history vá»›i bot reply (giá»‘ng GPT - nhá»› lá»‹ch sá»­)
    # User input Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trÆ°á»›c Ä‘Ã³, giá» chá»‰ cáº§n cáº­p nháº­t reply
    if "reply" in response and response["reply"]:
        history_list = state.get("conversation_history", [])
        # TÃ¬m entry cuá»‘i cÃ¹ng (cÃ¢u há»i hiá»‡n táº¡i) vÃ  cáº­p nháº­t reply
        if history_list and history_list[-1][1] is None:
            history_list[-1] = (history_list[-1][0], response["reply"])
        else:
            # Náº¿u khÃ´ng tÃ¬m tháº¥y, thÃªm má»›i (fallback)
            history_list.append((cleaned_input, response["reply"]))
        
        # Giá»¯ tá»‘i Ä‘a 6 cáº·p Q&A gáº§n nháº¥t Ä‘á»ƒ khÃ´ng tá»‘n quÃ¡ nhiá»u token
        # (6 vÃ¬ cÃ³ thá»ƒ cÃ³ 1 entry chÆ°a cÃ³ reply)
        if len(history_list) > 6:
            history_list.pop(0)
        state["conversation_history"] = history_list
    
    # XÃ³a clarification question sau khi Ä‘Ã£ tráº£ lá»i
    if is_follow_up and "last_clarification_question" in state:
        state.pop("last_clarification_question", None)
        state.pop("last_user_input_before_clarification", None)
    
    return response


def chat(user_input: str, session_id: str = "default") -> str:
    result = run_chat_pipeline(user_input, session_id=session_id)
    return result["reply"]


# ============================
# VÃ’NG Láº¶P CHAT
# ============================

if __name__ == "__main__":
    while True:
        user = input("\nBáº¡n: ").strip()
        if user.lower() == "quit":
            print("Táº¡m biá»‡t báº¡n ğŸ‘‹ ChÃºc báº¡n nhiá»u sá»©c khá»e!")
            break

        reply = chat(user, session_id="cli")
        print("Bot:", reply)
