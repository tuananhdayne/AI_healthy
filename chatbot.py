# chatbot.py

from threading import Lock
from typing import Any, Dict, Optional

from intent.intent_classifier import IntentClassifier
from rag.retriever import Retriever
from generator.gemini_generator import generate_medical_answer
from app.response_layer import need_more_info, build_clarification_question
from app.symptom_extractor import extract_symptoms
from app.risk_estimator import estimate_risk

# ============================
# KH·ªûI T·∫†O C√ÅC MODEL (LAZY LOADING)
# ============================

intent_model_path = r"D:\CHAT BOT TTCS\model\intent_model"
rag_path = r"D:\CHAT BOT TTCS\rag"

# Kh√¥ng load models ngay khi import - s·∫Ω load khi c·∫ßn
intent_classifier: Optional[IntentClassifier] = None
retriever: Optional[Retriever] = None
_models_initialized = False
_models_lock = Lock()

conversation_states: Dict[str, Dict[str, Any]] = {}
conversation_lock = Lock()


def _ensure_models_loaded():
    """ƒê·∫£m b·∫£o models ƒë√£ ƒë∆∞·ª£c load"""
    global intent_classifier, retriever, _models_initialized
    
    if _models_initialized:
        return
    
    with _models_lock:
        if _models_initialized:  # Double check
            return
        
        print("üîÑ ƒêang kh·ªüi t·∫°o models trong chatbot module...")
        
        # Load Intent Classifier
        if intent_classifier is None:
            intent_classifier = IntentClassifier(intent_model_path)
        
        # Load RAG Retriever
        if retriever is None:
            retriever = Retriever(rag_path)
        
        # Gemini API kh√¥ng c·∫ßn load model, ch·ªâ c·∫ßn ki·ªÉm tra API key
        from generator.gemini_generator import _get_model
        try:
            _get_model()  # Test API connection
        except Exception as e:
            print(f"‚ö†Ô∏è C·∫£nh b√°o: Kh√¥ng th·ªÉ k·∫øt n·ªëi Gemini API: {e}")
            print("   H·ªá th·ªëng v·∫´n s·∫Ω ho·∫°t ƒë·ªông nh∆∞ng c√≥ th·ªÉ g·∫∑p l·ªói khi generate answer")
        
        _models_initialized = True
        print("‚úÖ Models trong chatbot module ƒë√£ s·∫µn s√†ng!")

# Ch·ªâ in message n√†y khi ch·∫°y tr·ª±c ti·∫øp (kh√¥ng ph·∫£i khi import)
if __name__ == "__main__":
    # Khi ch·∫°y tr·ª±c ti·∫øp, load models ngay
    _ensure_models_loaded()
    print("ü§ñ Chatbot y t·∫ø s·∫µn s√†ng. Nh·∫≠p 'quit' ƒë·ªÉ tho√°t.\n")


# ============================
# QU·∫¢N L√ù TR·∫†NG TH√ÅI H·ªòI THO·∫†I
# ============================


def _get_or_create_state(session_id: str) -> Dict[str, Any]:
    with conversation_lock:
        if session_id not in conversation_states:
            conversation_states[session_id] = {
                "last_intent": None,
                "last_symptoms": None,
                "conversation_history": []  # L∆∞u l·ªãch s·ª≠ h·ªôi tho·∫°i (t·ªëi ƒëa 5 c·∫∑p Q&A g·∫ßn nh·∫•t)
            }
        return conversation_states[session_id]


def reset_conversation(session_id: str) -> None:
    with conversation_lock:
        conversation_states.pop(session_id, None)


# ============================
# H√ÄM CHAT CH√çNH
# ============================


def run_chat_pipeline(user_input: str, session_id: str = "default", user_id: Optional[str] = None) -> Dict[str, Any]:
    # ƒê·∫£m b·∫£o models ƒë√£ ƒë∆∞·ª£c load
    _ensure_models_loaded()
    
    cleaned_input = (user_input or "").strip()

    if not cleaned_input:
        return {
            "session_id": session_id,
            "reply": "B·∫°n h√£y nh·∫≠p c√¢u h·ªèi ho·∫∑c m√¥ t·∫£ tri·ªáu ch·ª©ng c·ª• th·ªÉ h∆°n nh√©.",
            "intent": None,
            "intent_confidence": 0.0,
            "symptoms": {},
            "risk": None,
            "clarification_needed": False,
            "clarification_question": None,
            "sources": [],
            "stage": "validation"
        }

    state = _get_or_create_state(session_id)

    # 1) Intent
    intent, intent_conf = intent_classifier.predict_with_conf(cleaned_input)
    print(f"üß† Intent: {intent} | conf={intent_conf:.2f}")

    # 2) Symptom Extraction
    symptoms = extract_symptoms(cleaned_input)
    risk = estimate_risk(symptoms)

    # 3) L∆∞u v√†o memory
    state["last_intent"] = intent
    state["last_symptoms"] = symptoms
    state["last_user_input"] = cleaned_input
    
    # L∆∞u user input v√†o conversation history ngay (tr∆∞·ªõc khi generate reply)
    history_list = state.get("conversation_history", [])
    # L∆∞u user input v·ªõi bot reply = None (s·∫Ω c·∫≠p nh·∫≠t sau)
    history_list.append((cleaned_input, None))
    state["conversation_history"] = history_list

    response: Dict[str, Any] = {
        "session_id": session_id,
        "intent": intent,
        "intent_confidence": float(intent_conf),
        "symptoms": symptoms,
        "risk": risk,
        "clarification_needed": False,
        "clarification_question": None,
        "sources": [],
        "stage": "generation"
    }

    # 4) Ng∆∞·ªùi d√πng n√≥i ti·∫øp c√°c t·ª´ m∆° h·ªì: "v·∫´n th·∫ø", "ƒë·ª° h∆°n r·ªìi"
    if cleaned_input.lower() in ["v·∫´n th·∫ø", "nh∆∞ h√¥m qua", "ƒë·ª° h∆°n", "n·∫∑ng h∆°n"]:
        last = state.get("last_symptoms")
        if last:
            response["reply"] = (
                "üí¨ B·∫°n ƒëang n√≥i v·ªÅ tri·ªáu ch·ª©ng tr∆∞·ªõc ƒë√≥. B·∫°n c√≥ th·ªÉ m√¥ t·∫£ th√™m kh√¥ng? "
                f"M√¨nh ghi nh·∫≠n l·∫ßn tr∆∞·ªõc l√†: {last}"
            )
        else:
            response["reply"] = "B·∫°n m√¥ t·∫£ tri·ªáu ch·ª©ng hi·ªán t·∫°i r√µ h∆°n nh√©!"
        response["stage"] = "follow_up"
        return response

    # 5) RISK LAYER ‚Äî ph√°t hi·ªán nguy hi·ªÉm
    if risk == "high":
        danger_signs = symptoms.get("danger_signs") or []
        danger_text = ", ".join(danger_signs) if danger_signs else "d·∫•u hi·ªáu nguy hi·ªÉm"
        response["reply"] = (
            "‚ö†Ô∏è M√¨nh ph√°t hi·ªán c√≥ d·∫•u hi·ªáu nguy hi·ªÉm nh∆∞: "
            + danger_text
            + ". B·∫°n n√™n ƒëi kh√°m b√°c sƒ© c√†ng s·ªõm c√†ng t·ªët ƒë·ªÉ ƒë·∫£m b·∫£o an to√†n."
        )
        response["stage"] = "safety"
        return response

    # 6) CLARIFICATION LAYER ‚Äî ch·ªâ h·ªèi khi th·ª±c s·ª± kh√¥ng r√µ tri·ªáu ch·ª©ng
    # KH√îNG h·ªèi m·∫∑c ƒë·ªãnh, ch·ªâ h·ªèi khi c√¢u r·∫•t m∆° h·ªì
    if need_more_info(cleaned_input, intent):
        question = build_clarification_question(intent)
        response["reply"] = (
            "üí¨ ƒê·ªÉ hi·ªÉu r√µ h∆°n v√† tr·∫£ l·ªùi ch√≠nh x√°c, b·∫°n cho m√¨nh bi·∫øt th√™m nh√©:\n"
            f"{question}"
        )
        response["clarification_needed"] = True
        response["clarification_question"] = question
        response["stage"] = "clarification"
        # L∆∞u c√¢u h·ªèi clarification v√†o state
        state["last_clarification_question"] = question
        state["last_user_input_before_clarification"] = cleaned_input
        return response

    # 7) RAG RETRIEVAL - T√¨m th√¥ng tin trong database
    # Logic m·ªõi: N·∫øu intent confidence >= 0.998 ‚Üí search RAG theo intent
    # N·∫øu intent l√† "other"/"unknown" ho·∫∑c confidence < 0.98 ‚Üí d√πng Gemini t·ª± do
    
    use_rag = False
    context = ""
    docs = []
    
    # Ki·ªÉm tra intent confidence
    if intent_conf >= 0.998 and intent not in ["other", "unknown"]:
        # Intent confidence cao ‚Üí search RAG theo intent
        print(f"‚úÖ Intent confidence cao ({intent_conf:.3f}), search RAG theo intent: {intent}")
        try:
            docs = retriever.search_by_intent(intent, cleaned_input, k=3)
            response["sources"] = docs
            
            # T√≠nh confidence t·ª´ RAG results
            rag_confidence = docs[0]["confidence"] if docs else 0.0
            rag_cosine = docs[0]["cosine"] if docs else -1.0
            
            print(f"üìö RAG Confidence: {rag_confidence:.3f} | Cosine: {rag_cosine:.3f}")
            
            # X√¢y d·ª±ng context t·ª´ RAG
            context = "\n".join([d["text"] for d in docs]) if docs else ""
            use_rag = True
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói khi search RAG theo intent: {e}, fallback v·ªÅ search th√¥ng th∆∞·ªùng")
            docs = retriever.search(cleaned_input, k=3)
            response["sources"] = docs
            context = "\n".join([d["text"] for d in docs]) if docs else ""
            use_rag = True
    elif intent in ["other", "unknown"] or intent_conf < 0.98:
        # Intent l√† "other"/"unknown" ho·∫∑c confidence th·∫•p ‚Üí d√πng Gemini t·ª± do (kh√¥ng search RAG)
        print(f"‚ö†Ô∏è Intent '{intent}' v·ªõi confidence {intent_conf:.3f} < 0.98, d√πng Gemini t·ª± do")
        response["sources"] = []
        context = ""  # Kh√¥ng c√≥ context t·ª´ RAG
        use_rag = False
    else:
        # Tr∆∞·ªùng h·ª£p kh√°c: search RAG th√¥ng th∆∞·ªùng
        docs = retriever.search(cleaned_input, k=3)
        response["sources"] = docs
        
        # T√≠nh confidence t·ª´ RAG results
        rag_confidence = docs[0]["confidence"] if docs else 0.0
        rag_cosine = docs[0]["cosine"] if docs else -1.0
        
        print(f"üìö RAG Confidence: {rag_confidence:.3f} | Cosine: {rag_cosine:.3f}")
        
        # X√¢y d·ª±ng context t·ª´ RAG
        context = "\n".join([d["text"] for d in docs]) if docs else ""
        use_rag = True

    # 8) L·∫§Y HEALTH PROFILE (n·∫øu c√≥ user_id)
    health_profile_context = ""
    if user_id:
        try:
            from firestore_service import get_health_profile
            profile = get_health_profile(user_id)
            if profile:
                # T√≠nh BMI
                chieu_cao_m = profile.get('chieuCao', 0) / 100
                can_nang = profile.get('canNang', 0)
                bmi = can_nang / (chieu_cao_m ** 2) if chieu_cao_m > 0 else 0
                
                # X√°c ƒë·ªãnh category BMI
                if bmi < 18.5:
                    bmi_category = "h∆°i g·∫ßy"
                elif bmi < 25:
                    bmi_category = "c√¢n ƒë·ªëi"
                elif bmi < 30:
                    bmi_category = "h∆°i th·ª´a c√¢n"
                else:
                    bmi_category = "th·ª´a c√¢n nhi·ªÅu"
                
                # Chuy·ªÉn ƒë·ªïi m·ª©c v·∫≠n ƒë·ªông
                muc_van_dong_labels = {
                    'it': '√çt',
                    'vua': 'V·ª´a',
                    'nhieu': 'Nhi·ªÅu'
                }
                muc_van_dong_label = muc_van_dong_labels.get(profile.get('mucVanDong', 'it'), '√çt')
                
                # Chuy·ªÉn ƒë·ªïi gi·ªõi t√≠nh
                gioi_tinh_labels = {
                    'nam': 'Nam',
                    'nu': 'N·ªØ',
                    'khac': 'Kh√°c'
                }
                gioi_tinh_label = gioi_tinh_labels.get(profile.get('gioiTinh', 'khac'), 'Kh√°c')
                
                # T·∫°o health profile context
                health_profile_context = f"""[PROFILE]
Tu·ªïi: {profile.get('tuoi', 'N/A')}
Gi·ªõi t√≠nh: {gioi_tinh_label}
Chi·ªÅu cao: {profile.get('chieuCao', 'N/A')} cm
C√¢n n·∫∑ng: {profile.get('canNang', 'N/A')} kg
M·ª©c v·∫≠n ƒë·ªông: {muc_van_dong_label}
BMI: {bmi:.1f} ({bmi_category})
[/PROFILE]

D·ª±a v√†o h·ªì s∆° tr√™n, h√£y ƒë∆∞a ra g·ª£i √Ω t·∫≠p luy·ªán nh·∫π, an to√†n, d·ªÖ th·ª±c hi·ªán ph√π h·ª£p v·ªõi:
- BMI: {bmi_category} ({bmi:.1f})
- Gi·ªõi t√≠nh: {gioi_tinh_label}
- M·ª©c v·∫≠n ƒë·ªông hi·ªán t·∫°i: {muc_van_dong_label}
- Tu·ªïi: {profile.get('tuoi', 'N/A')}

QUAN TR·ªåNG: Kh√¥ng ƒë∆∞·ª£c ch·∫©n ƒëo√°n b·ªánh, kh√¥ng ƒë∆∞·ª£c g·ª£i √Ω thu·ªëc. Ch·ªâ ƒë∆∞a ra l·ªùi khuy√™n t·∫≠p luy·ªán v√† l·ªëi s·ªëng nh·∫π nh√†ng, an to√†n.

"""
                print(f"üìã ƒê√£ load health profile cho user {user_id[:8]}... (BMI: {bmi:.1f}, {bmi_category})")
        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ load health profile: {e}")
            health_profile_context = ""

    # 10) PH√ÇN T·∫¶NG TR·∫¢ L·ªúI
    # M·ª©c 1: RAG confidence cao (>= 0.7) ‚Üí Tr·∫£ l·ªùi d·ª±a v√†o data
    # M·ª©c 2: RAG confidence th·∫•p (< 0.7) ‚Üí D√πng Gemini
    # M·ª©c 3: Risk cao ho·∫∑c kh√¥ng ch·∫Øc ch·∫Øn ‚Üí Tr·∫£ l·ªùi an to√†n, khuy√™n g·∫∑p b√°c sƒ©
    
    # X√¢y d·ª±ng conversation history ƒë·ªÉ bot nh·ªõ ng·ªØ c·∫£nh (gi·ªëng GPT - nh·ªõ nhi·ªÅu v√≤ng h·ªôi tho·∫°i)
    conversation_history = None
    is_follow_up = False
    
    # L·∫•y l·ªãch s·ª≠ h·ªôi tho·∫°i t·ª´ state (t·ªëi ƒëa 5 c·∫∑p Q&A g·∫ßn nh·∫•t)
    history_list = state.get("conversation_history", [])
    
    # L·ªçc b·ªè entry cu·ªëi c√πng n·∫øu ch∆∞a c√≥ reply (ƒë√≥ l√† c√¢u h·ªèi hi·ªán t·∫°i)
    # Ch·ªâ l·∫•y c√°c c·∫∑p Q&A ƒë√£ ho√†n ch·ªânh
    complete_history = [(q, a) for q, a in history_list if a is not None]
    
    # Debug: In ra conversation history ƒë·ªÉ ki·ªÉm tra
    if complete_history:
        print(f"üìù Conversation history c√≥ {len(complete_history)} c·∫∑p Q&A:")
        for i, (q, a) in enumerate(complete_history[-3:], 1):
            print(f"   {i}. User: {q[:50]}... | Bot: {a[:50] if a else 'None'}...")
    
    # Ki·ªÉm tra xem c√≥ ph·∫£i c√¢u tr·∫£ l·ªùi ti·∫øp theo sau clarification kh√¥ng
    last_clarification_question = state.get("last_clarification_question")
    last_user_input_before_clarification = state.get("last_user_input_before_clarification")
    last_intent = state.get("last_intent")
    last_symptoms = state.get("last_symptoms")
    
    # X√¢y d·ª±ng conversation history t·ª´ nhi·ªÅu ngu·ªìn
    history_parts = []
    
    # 1. N·∫øu c√≥ clarification question tr∆∞·ªõc ƒë√≥
    if last_clarification_question and last_user_input_before_clarification:
        is_follow_up = True
        history_parts.append("L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán:")
        history_parts.append(f"üë§ Ng∆∞·ªùi d√πng: \"{last_user_input_before_clarification}\"")
        history_parts.append(f"ü§ñ B·∫°n: \"{last_clarification_question}\"")
        history_parts.append(f"\nüëâ B√¢y gi·ªù ng∆∞·ªùi d√πng tr·∫£ l·ªùi: \"{cleaned_input}\"")
    # 2. N·∫øu c√≥ l·ªãch s·ª≠ h·ªôi tho·∫°i t·ª´ c√°c l·∫ßn tr∆∞·ªõc (Q&A ƒë√£ ho√†n ch·ªânh)
    elif complete_history:
        is_follow_up = True
        history_parts.append("L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc ƒë√≥:")
        # L·∫•y 4-5 c·∫∑p g·∫ßn nh·∫•t ƒë·ªÉ c√≥ ƒë·ªß ng·ªØ c·∫£nh
        for i, (q, a) in enumerate(complete_history[-5:], 1):
            history_parts.append(f"\n[{i}] üë§ Ng∆∞·ªùi d√πng: {q}")
            history_parts.append(f"    ü§ñ B·∫°n: {a}")
        history_parts.append(f"\nüëâ B√¢y gi·ªù ng∆∞·ªùi d√πng h·ªèi: \"{cleaned_input}\"")
    # 3. N·∫øu c√≥ th√¥ng tin t·ª´ l·∫ßn tr∆∞·ªõc (intent, symptoms) nh∆∞ng ch∆∞a c√≥ history ƒë·∫ßy ƒë·ªß
    elif last_intent and last_symptoms and not complete_history:
        is_follow_up = True
        history_parts.append("Th√¥ng tin t·ª´ cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc:")
        history_parts.append(f"üë§ Ng∆∞·ªùi d√πng ƒë√£ m√¥ t·∫£ v·ªÅ: {last_intent}")
        if last_symptoms.get("location"):
            history_parts.append(f"   - V·ªã tr√≠: {last_symptoms.get('location')}")
        if last_symptoms.get("intensity"):
            history_parts.append(f"   - M·ª©c ƒë·ªô: {last_symptoms.get('intensity')}")
        history_parts.append(f"\nüëâ B√¢y gi·ªù ng∆∞·ªùi d√πng h·ªèi: \"{cleaned_input}\"")
    
    if history_parts:
        conversation_history = "\n".join(history_parts)
        is_follow_up = True  # ƒê·∫£m b·∫£o is_follow_up = True n·∫øu c√≥ history

    # 9) TH√äM HEALTH PROFILE CONTEXT V√ÄO CONTEXT (n·∫øu c√≥)
    if health_profile_context:
        # Th√™m health profile context v√†o ƒë·∫ßu context
        if context:
            context = health_profile_context + "\n\n" + context
        else:
            context = health_profile_context

    # 11) PH√ÇN T·∫¶NG TR·∫¢ L·ªúI
    # Logic m·ªõi: N·∫øu ƒë√£ search RAG theo intent (confidence >= 0.998) ‚Üí d√πng RAG
    # N·∫øu intent l√† "other"/"unknown" ho·∫∑c confidence < 0.98 ‚Üí d√πng Gemini t·ª± do
    
    if use_rag and context:
        # ƒê√£ search RAG theo intent ‚Üí tr·∫£ l·ªùi d·ª±a v√†o RAG
        rag_confidence = docs[0]["confidence"] if docs else 0.0
        print(f"‚úÖ D√πng RAG v·ªõi confidence: {rag_confidence:.3f}")
        response["stage"] = "rag_high_confidence"
        response["reply"] = generate_medical_answer(
            context=context,
            user_question=cleaned_input,
            intent=intent,
            conversation_history=conversation_history,
            is_follow_up=is_follow_up,
            use_rag_priority=True  # ∆Øu ti√™n s·ª≠ d·ª•ng RAG context
        )
    else:
        # Intent l√† "other"/"unknown" ho·∫∑c confidence < 0.98 ‚Üí d√πng Gemini t·ª± do
        print("‚ö†Ô∏è D√πng Gemini t·ª± do (kh√¥ng c√≥ RAG context)")
        response["stage"] = "gemini_fallback"
        response["reply"] = generate_medical_answer(
            context="",  # Kh√¥ng c√≥ context t·ª´ RAG
            user_question=cleaned_input,
            intent=intent,
            conversation_history=conversation_history,
            is_follow_up=is_follow_up,
            use_rag_priority=False  # Kh√¥ng ∆∞u ti√™n RAG, ƒë·ªÉ Gemini t·ª± do
        )
    
    # M·ª©c n·ªØa: N·∫øu risk cao ho·∫∑c intent confidence th·∫•p ‚Üí Tr·∫£ l·ªùi an to√†n
    if risk == "high" or (intent_conf < 0.5 and response["stage"] not in ["safety", "rag_high_confidence"]):
        print("üõ°Ô∏è M·ª©c n·ªØa: Risk cao ho·∫∑c kh√¥ng ch·∫Øc ch·∫Øn, tr·∫£ l·ªùi an to√†n")
        safety_message = (
            "‚ö†Ô∏è D·ª±a tr√™n th√¥ng tin b·∫°n cung c·∫•p, t√¥i khuy√™n b·∫°n n√™n ƒëi g·∫∑p b√°c sƒ© ƒë·ªÉ ƒë∆∞·ª£c "
            "t∆∞ v·∫•n v√† ki·ªÉm tra ch√≠nh x√°c. T√¥i ch·ªâ c√≥ th·ªÉ cung c·∫•p th√¥ng tin tham kh·∫£o, "
            "kh√¥ng th·ªÉ thay th·∫ø cho ch·∫©n ƒëo√°n y t·∫ø chuy√™n nghi·ªáp.\n\n"
        )
        if response["reply"]:
            response["reply"] = safety_message + response["reply"]
        else:
            response["reply"] = safety_message + "Vui l√≤ng li√™n h·ªá v·ªõi b√°c sƒ© c√†ng s·ªõm c√†ng t·ªët."
        response["stage"] = "safety_recommendation"
    
    # C·∫≠p nh·∫≠t conversation history v·ªõi bot reply (gi·ªëng GPT - nh·ªõ l·ªãch s·ª≠)
    # User input ƒë√£ ƒë∆∞·ª£c l∆∞u tr∆∞·ªõc ƒë√≥, gi·ªù ch·ªâ c·∫ßn c·∫≠p nh·∫≠t reply
    if "reply" in response and response["reply"]:
        history_list = state.get("conversation_history", [])
        # T√¨m entry cu·ªëi c√πng (c√¢u h·ªèi hi·ªán t·∫°i) v√† c·∫≠p nh·∫≠t reply
        if history_list and history_list[-1][1] is None:
            history_list[-1] = (history_list[-1][0], response["reply"])
        else:
            # N·∫øu kh√¥ng t√¨m th·∫•y, th√™m m·ªõi (fallback)
            history_list.append((cleaned_input, response["reply"]))
        
        # Gi·ªØ t·ªëi ƒëa 6 c·∫∑p Q&A g·∫ßn nh·∫•t ƒë·ªÉ kh√¥ng t·ªën qu√° nhi·ªÅu token
        # (6 v√¨ c√≥ th·ªÉ c√≥ 1 entry ch∆∞a c√≥ reply)
        if len(history_list) > 6:
            history_list.pop(0)
        state["conversation_history"] = history_list
    
    # X√≥a clarification question sau khi ƒë√£ tr·∫£ l·ªùi
    if is_follow_up and "last_clarification_question" in state:
        state.pop("last_clarification_question", None)
        state.pop("last_user_input_before_clarification", None)
    
    return response


def chat(user_input: str, session_id: str = "default") -> str:
    result = run_chat_pipeline(user_input, session_id=session_id)
    return result["reply"]


# ============================
# V√íNG L·∫∂P CHAT
# ============================

if __name__ == "__main__":
    while True:
        user = input("\nB·∫°n: ").strip()
        if user.lower() == "quit":
            print("T·∫°m bi·ªát b·∫°n üëã Ch√∫c b·∫°n nhi·ªÅu s·ª©c kh·ªèe!")
            break

        reply = chat(user, session_id="cli")
        print("Bot:", reply)
